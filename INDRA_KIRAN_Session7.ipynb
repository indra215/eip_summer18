{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DNST_CIFAR10_AUG.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [
        {
          "file_id": "1_1kwmwgL7g94jI6BEtcgm-D2_AFk0zxK",
          "timestamp": 1519101209834
        }
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "RvadpM4fvxOA",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import math\n",
        "import numpy as np\n",
        "\n",
        "import keras.backend as K\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D\n",
        "\n",
        "#from utils import L2Normalization"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0vZChxntvzvw",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "num_classes = 2\n",
        "share_location = True\n",
        "\n",
        "config = {\n",
        "\t'run_soon': True,\n",
        "\t'resume_training': True,\n",
        "\t'remove_old_models': False,\n",
        "\t'denser_prior_boxes': True,\n",
        "\t'use_polygon': True,\n",
        "\t'train_data': \"./data/train_lmdb/\",\n",
        "\t'test_data': \"./data/test_lmdb/\",\n",
        "\t'resize_width': 384,\n",
        "\t'resize_height': 384,\n",
        "\t'lr_mult': 1,\n",
        "\t'base_lr': 0.0001,\n",
        "\t'pretrain_model': \"models/model_pre_train_syn.caffemodel\",\n",
        "\t'label_map_file': \"data/text/labelmap_voc.prototxt\",\n",
        "\t'flip': True,\n",
        "\t'clip': False,\n",
        "}\n",
        "\n",
        "min_dim = 300\n",
        "mbox_source_layers = ['conv4_3', 'fc7', 'conv6_2', 'conv7_2', 'conv8_2', 'conv9_2']\n",
        "# in percent %\n",
        "min_ratio = 10\n",
        "max_ratio = 90\n",
        "step = int(math.floor((max_ratio - min_ratio) / (len(mbox_source_layers) - 2)))\n",
        "min_sizes = []\n",
        "max_sizes = []\n",
        "for ratio in range(min_ratio, max_ratio + 1, step):\n",
        "    min_sizes.append(min_dim * ratio / 100.)\n",
        "    max_sizes.append(min_dim * (ratio + step) / 100.)\n",
        "min_sizes = [min_dim * 10 / 100.] + min_sizes\n",
        "max_sizes = [min_dim * 20 / 100.] + max_sizes\n",
        "steps = [8, 16, 32, 64, 100, 300]\n",
        "# aspect_ratios = [[2], [2, 3], [2, 3], [2, 3], [2], [2]]\n",
        "aspect_ratios = [[2,3,4,5], [2,3,4,5], [2,3,4,5], [2,3,4,5], [2,3,4,5], [2,3,4,5]]\n",
        "# L2 normalize conv4_3.\n",
        "normalizations = [20, -1, -1, -1, -1, -1]\n",
        "# variance used to encode/decode prior bboxes.\n",
        "prior_variance = [0.1, 0.1, 0.2, 0.2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SRCuRP8Iv1xM",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def CreatedMultihead_Multitask(input_tensor,\n",
        "                                    from_layers,\n",
        "                                    min_sizes,\n",
        "                                    max_sizes,\n",
        "                                    use_polygon,\n",
        "                                    aspect_ratios,\n",
        "                                    steps,\n",
        "                                    normalizations,\n",
        "                                    num_classes,\n",
        "                                    share_location,\n",
        "                                    flip,\n",
        "                                    clip,\n",
        "                                    prior_variance,\n",
        "                                    denser_prior_boxes,\n",
        "                                    kernel_size,\n",
        "                                    pad):\n",
        "    ''' creates the top layer network for detecting the bounding boxes '''\n",
        "\n",
        "    assert num_classes, \"must provide num_classes\"\n",
        "    assert num_classes > 0, \"num_classes must be positive number\"\n",
        "    if normalizations:\n",
        "        assert len(from_layers) == len(normalizations), \"from_layers and normalizations should have same length\"\n",
        "    assert len(from_layers) == len(min_sizes), \"from_layers and min_sizes should have same length\"\n",
        "    if max_sizes:\n",
        "        assert len(from_layers) == len(max_sizes), \"from_layers and max_sizes should have same length\"\n",
        "    if aspect_ratios:\n",
        "        assert len(from_layers) == len(aspect_ratios), \"from_layers and aspect_ratios should have same length\"\n",
        "    if steps:\n",
        "        assert len(from_layers) == len(steps), \"from_layers and steps should have same length\"\n",
        "\n",
        "    num = len(from_layers)\n",
        "    should_normalize = []\n",
        "    num_outputs_loc = []\n",
        "    num_outputs_conf = []\n",
        "    for i in range(0, num):\n",
        "        # Get the normalize value.\n",
        "        if normalizations:\n",
        "            if normalizations[i] != -1:\n",
        "                should_normalize.append(('True', normalizations[i]))\n",
        "\n",
        "        # Estimate number of priors per location given provided parameters.\n",
        "        min_size = min_sizes[i]\n",
        "        if type(min_size) is not list:\n",
        "            min_size = [min_size]\n",
        "        aspect_ratio = []\n",
        "        if len(aspect_ratios) > i:\n",
        "            aspect_ratio = aspect_ratios[i]\n",
        "            if type(aspect_ratio) is not list:\n",
        "                aspect_ratio = [aspect_ratio]\n",
        "        max_size = []\n",
        "        if len(max_sizes) > i:\n",
        "            max_size = max_sizes[i]\n",
        "            if type(max_size) is not list:\n",
        "                max_size = [max_size]\n",
        "            if max_size:\n",
        "                assert len(max_size) == len(min_size), \"max_size and min_size should have same length.\"\n",
        "        if max_size:\n",
        "            num_priors_per_location = (2 + len(aspect_ratio)) * len(min_size)\n",
        "        else:\n",
        "            num_priors_per_location = (1 + len(aspect_ratio)) * len(min_size)\n",
        "        if flip:\n",
        "            num_priors_per_location += len(aspect_ratio) * len(min_size)\n",
        "        step = []\n",
        "        if len(steps) > i:\n",
        "            step = steps[i]\n",
        "        if denser_prior_boxes:\n",
        "             num_priors_per_location=2*num_priors_per_location\n",
        "\n",
        "        # number of outputs for localizing layer\n",
        "        if use_polygon:\n",
        "            num_loc_output = num_priors_per_location * (4 + 8)\n",
        "        else:\n",
        "            num_loc_output = num_priors_per_location * (4 + 5)\n",
        "        if not share_location:\n",
        "            num_loc_output *= num_classes\n",
        "        num_outputs_loc.append(num_loc_output)\n",
        "\n",
        "        # number of outputs for confidence layer\n",
        "        num_conf_output = num_priors_per_location * num_classes\n",
        "        num_outputs_conf.append(num_conf_output)\n",
        "\n",
        "    return num_outputs_loc, num_outputs_conf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "popROlq1v3uC",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def VGG16Body(input_tensor, istrainable=True):\n",
        "    ''' fully convolutionized VGG model '''\n",
        "\n",
        "    # conv1\n",
        "    conv1_2 = Conv2D(64, (3, 3), activation='relu', padding='same', name='conv1_2', trainable=istrainable)(conv1_1)\n",
        "    conv1_1 = Conv2D(64, (3, 3), activation='relu', padding='same', name='conv1_1', trainable=istrainable)(input_tensor)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same', name='pool1')(conv1_2)\n",
        "\n",
        "    # conv2\n",
        "    conv2_1 = Conv2D(128, (3, 3), activation='relu', padding='same', name='conv2_1', trainable=istrainable)(pool1)\n",
        "    conv2_2 = Conv2D(128, (3, 3), activation='relu', padding='same', name='conv2_2', trainable=istrainable)(conv2_1)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same', name='pool2')(conv2_2)\n",
        "\n",
        "    # conv3\n",
        "    conv3_1 = Conv2D(256, (3, 3), activation='relu', padding='same', name='conv3_1')(pool2)\n",
        "    conv3_2 = Conv2D(256, (3, 3), activation='relu', padding='same', name='conv3_2')(conv3_1)\n",
        "    conv3_3 = Conv2D(256, (3, 3), activation='relu', padding='same', name='conv3_2')(conv3_2)\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same', name='pool3')(conv3_3)\n",
        "\n",
        "    # conv4\n",
        "    conv4_1 = Conv2D(512, (3, 3), activation='relu', padding='same', name='conv4_1')(pool3)\n",
        "    conv4_2 = Conv2D(512, (3, 3), activation='relu', padding='same', name='conv4_2')(conv4_1)\n",
        "    conv4_3 = Conv2D(512, (3, 3), activation='relu', padding='same', name='conv4_3')(conv4_2)\n",
        "    pool4 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same', name='pool4')(conv4_3)\n",
        "\n",
        "    # conv5\n",
        "    conv5_1 = Conv2D(512, (3, 3), activation='relu', padding='same', name='conv5_1')(pool4)\n",
        "    conv5_2 = Conv2D(512, (3, 3), activation='relu', padding='same', name='conv5_2')(conv5_1)\n",
        "    conv5_3 = Conv2D(512, (3, 3), activation='relu', padding='same', name='conv5_3')(conv5_2)\n",
        "    pool5 = MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding='same', name='pool5')(conv5_3)\n",
        "\n",
        "    # original VGG16 model has FC layer after Conv5 but here we want fully conv layer\n",
        "    # so we convert the original FC layers to conv layers\n",
        "    # conv6 (fc6)\n",
        "    conv6 = Conv2D(1024, (3, 3), dilation_rate=(6, 6), activation='relu', padding='same', name='conv6')(pool5)\n",
        "\n",
        "    # conv7\n",
        "    conv7 = Conv2D(1024, (1, 1), activation='relu', padding='same', name='conv7')(conv6)\n",
        "\n",
        "    return conv7"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uHWPmSgCv5gk",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def AddExtraLayers(input_tensor):\n",
        "    ''' extra convolution layers on top of VGG16 '''\n",
        "\n",
        "    # conv6\n",
        "    conv6_1 = Conv2D(256, (1, 1), activation='relu', padding='same', name='conv6_1')(input_tensor)\n",
        "    conv6_1 = ZeroPadding2D(padding=((1, 1), (1, 1)), name='conv6_padding')(conv6_1)\n",
        "    conv6_2 = Conv2D(512, (3, 3), strides=(2, 2), activation='relu', padding='valid', name='conv6_2')(conv6_1)\n",
        "\n",
        "    # conv7\n",
        "    conv7_1 = Conv2D(128, (1, 1), activation='relu', padding='same', name='conv7_1')(conv6_2)\n",
        "    conv7_1 = ZeroPadding2D(padding=((1, 1), (1, 1)), name='conv7_padding')(conv7_1)\n",
        "    conv7_2 = Conv2D(256, (3, 3), strides=(2, 2), activation='relu', padding='valid', name='conv7_2')(conv7_1)\n",
        "\n",
        "    # conv8\n",
        "    conv8_1 = Conv2D(128, (1, 1), activation='relu', padding='same', name='conv8_1')(conv7_2)\n",
        "    conv8_2 = Conv2D(256, (3, 3), strides=(1, 1), activation='relu', padding='valid', name='conv8_2')(conv8_1)\n",
        "\n",
        "    # conv9\n",
        "    conv9_1 = Conv2D(128, (1, 1), activation='relu', padding='same', name='conv9_1')(conv8_2)\n",
        "    conv9_2 = Conv2D(256, (3, 3), strides=(1, 1), activation='relu', padding='valid', name='conv9_2')(conv9_1)\n",
        "\n",
        "    return conv9_2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5dNk9Ccbv7cI",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def TextBoxesplusplusModel(image_shape,\n",
        "                        mean_subtraction,\n",
        "                        stddev_norm,\n",
        "                        swap_channels):\n",
        "    ''' full model of TextboxesPlusPlus '''\n",
        "\n",
        "    img_height, img_width, img_channels = image_shape[0], image_shape[1], image_shape[2]\n",
        "\n",
        "    #######################################################\n",
        "    # Define the lambda layers necessary\n",
        "    #######################################################\n",
        "    def image_identity_layer(input_tensor):\n",
        "        return input_tensor\n",
        "\n",
        "    def image_mean_subtraction_layer(input_tensor):\n",
        "        return input_tensor - np.array(mean_subtraction)\n",
        "\n",
        "    def image_stddev_norm_layer(input_tensor):\n",
        "        return input_tensor - np.array(stddev_norm)\n",
        "\n",
        "    def image_swap_channels_layer(input_tensor):\n",
        "        swap_tensor = K.stack([input_tensor[...,swap_channels[0]], input_tensor[..., swap_channels[1]], \\\n",
        "                                    input_tensor[..., swap_channels[2]]], axis=-1)\n",
        "        return swap_tensor\n",
        "\n",
        "    #######################################################\n",
        "    # Define the Textboxes++ model\n",
        "    #######################################################\n",
        "    x = Input(shape=(img_height, img_width, img_channels))\n",
        "\n",
        "    # create a identity layer for further use\n",
        "    x1 = Lambda(image_identity_layer, output_shape=image_shape, name='image_identity_layer')(x)\n",
        "\n",
        "    ''' apply the basic normalizations as applied '''\n",
        "    # mean subtraction\n",
        "    if mean_subtraction:\n",
        "        x1 = Lambda(image_mean_subtraction_layer, output_shape=image_shape, name='image_mean_subtraction')(x1)\n",
        "    # stddev normalization\n",
        "    if stddev_norm:\n",
        "        x1 = Lambda(image_stddev_norm_layer, output_shape=image_shape, name='image_stddev_norm')(x1)\n",
        "    # channel swap\n",
        "    if swap_channels:\n",
        "        x1 = Lambda(image_swap_channels_layer, output_shape=image_shape, name='image_swap_channels')(x1)\n",
        "\n",
        "    # fully convolutional VGG16 layer frontend\n",
        "    x1 = VGG16Body(x1)\n",
        "\n",
        "    # add extra convolution layers on TextboxesPlusPlus\n",
        "    x1 = AddExtraLayers(x1)\n",
        "\n",
        "    # normalize conv4_3 layer\n",
        "    conv4_3_norm = L2L2Normalization(gamma_init=20, name='conv4_3_norm')(conv4_3)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}